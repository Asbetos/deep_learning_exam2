UltimateSOTAModel(
  (backbone): SwinTransformerV2(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    )
    (layers): Sequential(
      (0): SwinTransformerV2Stage(
        (downsample): Identity()
        (blocks): ModuleList(
          (0): SwinTransformerV2Block(
            (attn): WindowAttention(
              (cpb_mlp): Sequential(
                (0): Linear(in_features=2, out_features=512, bias=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=512, out_features=6, bias=False)
              )
              (qkv): Linear(in_features=192, out_features=576, bias=False)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (drop_path1): Identity()
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (drop1): Dropout(p=0.0, inplace=False)
              (norm): Identity()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop2): Dropout(p=0.0, inplace=False)
            )
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (drop_path2): Identity()
          )
          (1): SwinTransformerV2Block(
            (attn): WindowAttention(
              (cpb_mlp): Sequential(
                (0): Linear(in_features=2, out_features=512, bias=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=512, out_features=6, bias=False)
              )
              (qkv): Linear(in_features=192, out_features=576, bias=False)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (drop_path1): DropPath(drop_prob=0.004)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (drop1): Dropout(p=0.0, inplace=False)
              (norm): Identity()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop2): Dropout(p=0.0, inplace=False)
            )
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (drop_path2): DropPath(drop_prob=0.004)
          )
        )
      )
      (1): SwinTransformerV2Stage(
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
        (blocks): ModuleList(
          (0): SwinTransformerV2Block(
            (attn): WindowAttention(
              (cpb_mlp): Sequential(
                (0): Linear(in_features=2, out_features=512, bias=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=512, out_features=12, bias=False)
              )
              (qkv): Linear(in_features=384, out_features=1152, bias=False)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (drop_path1): DropPath(drop_prob=0.009)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (drop1): Dropout(p=0.0, inplace=False)
              (norm): Identity()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop2): Dropout(p=0.0, inplace=False)
            )
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (drop_path2): DropPath(drop_prob=0.009)
          )
          (1): SwinTransformerV2Block(
            (attn): WindowAttention(
              (cpb_mlp): Sequential(
                (0): Linear(in_features=2, out_features=512, bias=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=512, out_features=12, bias=False)
              )
              (qkv): Linear(in_features=384, out_features=1152, bias=False)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (drop_path1): DropPath(drop_prob=0.013)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (drop1): Dropout(p=0.0, inplace=False)
              (norm): Identity()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop2): Dropout(p=0.0, inplace=False)
            )
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (drop_path2): DropPath(drop_prob=0.013)
          )
        )
      )
      (2): SwinTransformerV2Stage(
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (blocks): ModuleList(
          (0): SwinTransformerV2Block(
            (attn): WindowAttention(
              (cpb_mlp): Sequential(
                (0): Linear(in_features=2, out_features=512, bias=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=512, out_features=24, bias=False)
              )
              (qkv): Linear(in_features=768, out_features=2304, bias=False)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path1): DropPath(drop_prob=0.017)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (drop1): Dropout(p=0.0, inplace=False)
              (norm): Identity()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop2): Dropout(p=0.0, inplace=False)
            )
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path2): DropPath(drop_prob=0.017)
          )
          (1): SwinTransformerV2Block(
            (attn): WindowAttention(
              (cpb_mlp): Sequential(
                (0): Linear(in_features=2, out_features=512, bias=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=512, out_features=24, bias=False)
              )
              (qkv): Linear(in_features=768, out_features=2304, bias=False)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path1): DropPath(drop_prob=0.022)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (drop1): Dropout(p=0.0, inplace=False)
              (norm): Identity()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop2): Dropout(p=0.0, inplace=False)
            )
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path2): DropPath(drop_prob=0.022)
          )
          (2): SwinTransformerV2Block(
            (attn): WindowAttention(
              (cpb_mlp): Sequential(
                (0): Linear(in_features=2, out_features=512, bias=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=512, out_features=24, bias=False)
              )
              (qkv): Linear(in_features=768, out_features=2304, bias=False)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path1): DropPath(drop_prob=0.026)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (drop1): Dropout(p=0.0, inplace=False)
              (norm): Identity()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop2): Dropout(p=0.0, inplace=False)
            )
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path2): DropPath(drop_prob=0.026)
          )
          (3): SwinTransformerV2Block(
            (attn): WindowAttention(
              (cpb_mlp): Sequential(
                (0): Linear(in_features=2, out_features=512, bias=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=512, out_features=24, bias=False)
              )
              (qkv): Linear(in_features=768, out_features=2304, bias=False)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path1): DropPath(drop_prob=0.030)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (drop1): Dropout(p=0.0, inplace=False)
              (norm): Identity()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop2): Dropout(p=0.0, inplace=False)
            )
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path2): DropPath(drop_prob=0.030)
          )
          (4): SwinTransformerV2Block(
            (attn): WindowAttention(
              (cpb_mlp): Sequential(
                (0): Linear(in_features=2, out_features=512, bias=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=512, out_features=24, bias=False)
              )
              (qkv): Linear(in_features=768, out_features=2304, bias=False)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path1): DropPath(drop_prob=0.035)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (drop1): Dropout(p=0.0, inplace=False)
              (norm): Identity()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop2): Dropout(p=0.0, inplace=False)
            )
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path2): DropPath(drop_prob=0.035)
          )
          (5): SwinTransformerV2Block(
            (attn): WindowAttention(
              (cpb_mlp): Sequential(
                (0): Linear(in_features=2, out_features=512, bias=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=512, out_features=24, bias=False)
              )
              (qkv): Linear(in_features=768, out_features=2304, bias=False)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path1): DropPath(drop_prob=0.039)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (drop1): Dropout(p=0.0, inplace=False)
              (norm): Identity()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop2): Dropout(p=0.0, inplace=False)
            )
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path2): DropPath(drop_prob=0.039)
          )
          (6): SwinTransformerV2Block(
            (attn): WindowAttention(
              (cpb_mlp): Sequential(
                (0): Linear(in_features=2, out_features=512, bias=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=512, out_features=24, bias=False)
              )
              (qkv): Linear(in_features=768, out_features=2304, bias=False)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path1): DropPath(drop_prob=0.043)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (drop1): Dropout(p=0.0, inplace=False)
              (norm): Identity()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop2): Dropout(p=0.0, inplace=False)
            )
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path2): DropPath(drop_prob=0.043)
          )
          (7): SwinTransformerV2Block(
            (attn): WindowAttention(
              (cpb_mlp): Sequential(
                (0): Linear(in_features=2, out_features=512, bias=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=512, out_features=24, bias=False)
              )
              (qkv): Linear(in_features=768, out_features=2304, bias=False)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path1): DropPath(drop_prob=0.048)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (drop1): Dropout(p=0.0, inplace=False)
              (norm): Identity()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop2): Dropout(p=0.0, inplace=False)
            )
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path2): DropPath(drop_prob=0.048)
          )
          (8): SwinTransformerV2Block(
            (attn): WindowAttention(
              (cpb_mlp): Sequential(
                (0): Linear(in_features=2, out_features=512, bias=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=512, out_features=24, bias=False)
              )
              (qkv): Linear(in_features=768, out_features=2304, bias=False)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path1): DropPath(drop_prob=0.052)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (drop1): Dropout(p=0.0, inplace=False)
              (norm): Identity()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop2): Dropout(p=0.0, inplace=False)
            )
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path2): DropPath(drop_prob=0.052)
          )
          (9): SwinTransformerV2Block(
            (attn): WindowAttention(
              (cpb_mlp): Sequential(
                (0): Linear(in_features=2, out_features=512, bias=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=512, out_features=24, bias=False)
              )
              (qkv): Linear(in_features=768, out_features=2304, bias=False)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path1): DropPath(drop_prob=0.057)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (drop1): Dropout(p=0.0, inplace=False)
              (norm): Identity()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop2): Dropout(p=0.0, inplace=False)
            )
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path2): DropPath(drop_prob=0.057)
          )
          (10): SwinTransformerV2Block(
            (attn): WindowAttention(
              (cpb_mlp): Sequential(
                (0): Linear(in_features=2, out_features=512, bias=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=512, out_features=24, bias=False)
              )
              (qkv): Linear(in_features=768, out_features=2304, bias=False)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path1): DropPath(drop_prob=0.061)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (drop1): Dropout(p=0.0, inplace=False)
              (norm): Identity()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop2): Dropout(p=0.0, inplace=False)
            )
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path2): DropPath(drop_prob=0.061)
          )
          (11): SwinTransformerV2Block(
            (attn): WindowAttention(
              (cpb_mlp): Sequential(
                (0): Linear(in_features=2, out_features=512, bias=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=512, out_features=24, bias=False)
              )
              (qkv): Linear(in_features=768, out_features=2304, bias=False)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path1): DropPath(drop_prob=0.065)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (drop1): Dropout(p=0.0, inplace=False)
              (norm): Identity()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop2): Dropout(p=0.0, inplace=False)
            )
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path2): DropPath(drop_prob=0.065)
          )
          (12): SwinTransformerV2Block(
            (attn): WindowAttention(
              (cpb_mlp): Sequential(
                (0): Linear(in_features=2, out_features=512, bias=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=512, out_features=24, bias=False)
              )
              (qkv): Linear(in_features=768, out_features=2304, bias=False)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path1): DropPath(drop_prob=0.070)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (drop1): Dropout(p=0.0, inplace=False)
              (norm): Identity()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop2): Dropout(p=0.0, inplace=False)
            )
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path2): DropPath(drop_prob=0.070)
          )
          (13): SwinTransformerV2Block(
            (attn): WindowAttention(
              (cpb_mlp): Sequential(
                (0): Linear(in_features=2, out_features=512, bias=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=512, out_features=24, bias=False)
              )
              (qkv): Linear(in_features=768, out_features=2304, bias=False)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path1): DropPath(drop_prob=0.074)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (drop1): Dropout(p=0.0, inplace=False)
              (norm): Identity()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop2): Dropout(p=0.0, inplace=False)
            )
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path2): DropPath(drop_prob=0.074)
          )
          (14): SwinTransformerV2Block(
            (attn): WindowAttention(
              (cpb_mlp): Sequential(
                (0): Linear(in_features=2, out_features=512, bias=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=512, out_features=24, bias=False)
              )
              (qkv): Linear(in_features=768, out_features=2304, bias=False)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path1): DropPath(drop_prob=0.078)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (drop1): Dropout(p=0.0, inplace=False)
              (norm): Identity()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop2): Dropout(p=0.0, inplace=False)
            )
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path2): DropPath(drop_prob=0.078)
          )
          (15): SwinTransformerV2Block(
            (attn): WindowAttention(
              (cpb_mlp): Sequential(
                (0): Linear(in_features=2, out_features=512, bias=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=512, out_features=24, bias=False)
              )
              (qkv): Linear(in_features=768, out_features=2304, bias=False)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path1): DropPath(drop_prob=0.083)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (drop1): Dropout(p=0.0, inplace=False)
              (norm): Identity()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop2): Dropout(p=0.0, inplace=False)
            )
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path2): DropPath(drop_prob=0.083)
          )
          (16): SwinTransformerV2Block(
            (attn): WindowAttention(
              (cpb_mlp): Sequential(
                (0): Linear(in_features=2, out_features=512, bias=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=512, out_features=24, bias=False)
              )
              (qkv): Linear(in_features=768, out_features=2304, bias=False)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path1): DropPath(drop_prob=0.087)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (drop1): Dropout(p=0.0, inplace=False)
              (norm): Identity()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop2): Dropout(p=0.0, inplace=False)
            )
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path2): DropPath(drop_prob=0.087)
          )
          (17): SwinTransformerV2Block(
            (attn): WindowAttention(
              (cpb_mlp): Sequential(
                (0): Linear(in_features=2, out_features=512, bias=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=512, out_features=24, bias=False)
              )
              (qkv): Linear(in_features=768, out_features=2304, bias=False)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path1): DropPath(drop_prob=0.091)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (drop1): Dropout(p=0.0, inplace=False)
              (norm): Identity()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop2): Dropout(p=0.0, inplace=False)
            )
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (drop_path2): DropPath(drop_prob=0.091)
          )
        )
      )
      (3): SwinTransformerV2Stage(
        (downsample): PatchMerging(
          (reduction): Linear(in_features=3072, out_features=1536, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
        (blocks): ModuleList(
          (0): SwinTransformerV2Block(
            (attn): WindowAttention(
              (cpb_mlp): Sequential(
                (0): Linear(in_features=2, out_features=512, bias=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=512, out_features=48, bias=False)
              )
              (qkv): Linear(in_features=1536, out_features=4608, bias=False)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=1536, out_features=1536, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            (drop_path1): DropPath(drop_prob=0.096)
            (mlp): Mlp(
              (fc1): Linear(in_features=1536, out_features=6144, bias=True)
              (act): GELU()
              (drop1): Dropout(p=0.0, inplace=False)
              (norm): Identity()
              (fc2): Linear(in_features=6144, out_features=1536, bias=True)
              (drop2): Dropout(p=0.0, inplace=False)
            )
            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            (drop_path2): DropPath(drop_prob=0.096)
          )
          (1): SwinTransformerV2Block(
            (attn): WindowAttention(
              (cpb_mlp): Sequential(
                (0): Linear(in_features=2, out_features=512, bias=True)
                (1): ReLU(inplace=True)
                (2): Linear(in_features=512, out_features=48, bias=False)
              )
              (qkv): Linear(in_features=1536, out_features=4608, bias=False)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=1536, out_features=1536, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            (drop_path1): DropPath(drop_prob=0.100)
            (mlp): Mlp(
              (fc1): Linear(in_features=1536, out_features=6144, bias=True)
              (act): GELU()
              (drop1): Dropout(p=0.0, inplace=False)
              (norm): Identity()
              (fc2): Linear(in_features=6144, out_features=1536, bias=True)
              (drop2): Dropout(p=0.0, inplace=False)
            )
            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            (drop_path2): DropPath(drop_prob=0.100)
          )
        )
      )
    )
    (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
    (head): ClassifierHead(
      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())
      (drop): Dropout(p=0.0, inplace=False)
      (fc): Identity()
      (flatten): Identity()
    )
  )
  (classifier): Sequential(
    (0): Dropout(p=0.3, inplace=False)
    (1): Linear(in_features=1536, out_features=768, bias=True)
    (2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (3): GELU(approximate='none')
    (4): Dropout(p=0.2, inplace=False)
    (5): Linear(in_features=768, out_features=384, bias=True)
    (6): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (7): GELU(approximate='none')
    (8): Dropout(p=0.1, inplace=False)
    (9): Linear(in_features=384, out_features=10, bias=True)
  )
)
